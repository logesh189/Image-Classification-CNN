{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1)IMPORTING LIBRARIES\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator    #combine serveral images into one single image by rotating,flipping,cropping\n",
    "import numpy as np\n",
    "from keras.models import Sequential                      #used to create different layers for Neural Network\n",
    "from keras.layers import Conv2D,MaxPooling2D           #extract the feature sothe picture,reduce the size of the picture\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation,Dropout,Flatten,Dense\n",
    "\n",
    "#Activation function tells the Neural Network when it is Activate 1 or 0 or -1\n",
    "#Flatten convert 2D array to 1D array\n",
    "#Dense - to create the hidden and output layers\n",
    "\n",
    "from keras.preprocessing import image    #to load images from the Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)GENERATION OF DATA\n",
    "\n",
    "img_width,img_height=200,200\n",
    "train_dir = 'E:\\\\HONEY WELL\\\\data1a\\\\training'\n",
    "test_dir = 'E:\\\\HONEY WELL\\\\data1a\\\\testing'\n",
    "no_train_img = 1000\n",
    "no_test_img = 100\n",
    "epochs = 10            #50 times one particular Batch is given as input to the model\n",
    "batch_size = 20        #ONE BATCH carries 20 IMAGES, therefore 50 times it will get the Input from the Directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3)CHECKING THE IMAGE FORMAT\n",
    "\n",
    "if K.image_data_format() == 'channels first':         #channels first = RGB\n",
    "    input_shape = (3,img_width,img_height)\n",
    "else:\n",
    "    input_shape = (img_width,img_height,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4)GENERATE A SINGLE IMAGE BY FLIPPING,RESCALING,CROPPING\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1. /255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1. /255) #here just rescaling only Because it is Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1840 images belonging to 2 classes.\n",
      "Found 460 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#5)CREATING TRAINING GENERATOR AND TESTING GENERATOR by reading images from the diractories\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(img_width,img_height),batch_size=batch_size,class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,target_size=(img_width,img_height),batch_size=batch_size,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 198, 198, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 97, 97, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 97, 97, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2166848   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,195,553\n",
      "Trainable params: 2,195,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#6)CREATING THE NEURAL NETWORK\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),input_shape=input_shape))       #32-->no.of features extracted from image (3,3)-->3x3 matrix\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#repeat\n",
    "model.add(Conv2D(32,(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#increase the no. of features extraction to 64\n",
    "model.add(Conv2D(64,(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())           #convert into single flatten 1D array (INPUT LAYER)\n",
    "model.add(Dense(64))           #here 64 features are as 64 nodes in input layer\n",
    "model.add(Activation('relu'))  #activate some function to generate the output layer\n",
    "model.add(Dropout(0.5))         #remove some errors\n",
    "model.add(Dense(1))             #convert to single Output layer\n",
    "model.add(Activation('sigmoid'))\n",
    "          \n",
    "model.summary()                #just view what are added to the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7)compile the model to MAKE A CONTAINER which ACCEPTS input AND GENERATES output\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 53s 1s/step - loss: 0.7611 - accuracy: 0.5170 - val_loss: 0.6707 - val_accuracy: 0.5300\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 54s 1s/step - loss: 0.6729 - accuracy: 0.6100 - val_loss: 0.6638 - val_accuracy: 0.6500\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.6361 - accuracy: 0.6570 - val_loss: 0.5936 - val_accuracy: 0.6900\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 61s 1s/step - loss: 0.6443 - accuracy: 0.6340 - val_loss: 0.4820 - val_accuracy: 0.7000\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 62s 1s/step - loss: 0.6125 - accuracy: 0.6720 - val_loss: 0.7548 - val_accuracy: 0.6700\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.5907 - accuracy: 0.7070 - val_loss: 0.5709 - val_accuracy: 0.7200\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 64s 1s/step - loss: 0.6253 - accuracy: 0.6910 - val_loss: 0.4559 - val_accuracy: 0.6900\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 64s 1s/step - loss: 0.5760 - accuracy: 0.7120 - val_loss: 0.6017 - val_accuracy: 0.7800\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 63s 1s/step - loss: 0.5751 - accuracy: 0.7260 - val_loss: 0.3564 - val_accuracy: 0.7200\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 67s 1s/step - loss: 0.5460 - accuracy: 0.7410 - val_loss: 0.7511 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x283d541ea48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=no_train_img // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps = no_test_img // batch_size\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999654]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we cannot use the Total Code to Implement it in Hardware instead we give the h5 file which implements all the functionalities of out neural network\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#prediction\n",
    "\n",
    "img_pred = image.load_img(r'E:\\HONEY WELL\\data1a\\testing\\damage\\0040.jpeg',target_size=(200,200))\n",
    "img_pred = image.img_to_array(img_pred)\n",
    "img_pred = np.expand_dims(img_pred,axis=0)\n",
    "\n",
    "result = model.predict(img_pred)\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = \"non-damaged\"\n",
    "else:\n",
    "    prediction = \"damaged\"\n",
    "    \n",
    "result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
